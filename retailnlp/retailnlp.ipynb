{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('retailnlp_env': venv)",
   "display_name": "Python 3.8.3 64-bit ('retailnlp_env': venv)",
   "metadata": {
    "interpreter": {
     "hash": "55339690331cfaf7d3748b23ed09a20d5bf6e9bc5abb6027a466483fc1e145fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import logging # type: ignore\n",
    "from pathlib import Path # type: ignore\n",
    "from datetime import datetime, timedelta # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import random # type: ignore\n",
    "import recordlinkage # type: ignore\n",
    "from recordlinkage.datasets import load_febrl4\n",
    "import fuzzymatcher\n",
    "from copy import deepcopy # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "# Set any display options and default values                                            #\n",
    "#########################################################################################\n",
    "pd.set_option('display.max_row', 1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "BASEDIR = 'C:\\\\Users\\\\simon\\\\Documents\\\\py_projects\\\\retailnlp\\\\retailnlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates full path and name for an output file - default assumes a log file and will auto create target folder if it doesn't exist\n",
    "class Filename:\n",
    "    def __init__(self, module_name='retailnlp', typeofile='log', suffix='.log', folder_name='logs', sep='_', term=''):\n",
    "        self.module_name = module_name\n",
    "        self.typeofile = typeofile\n",
    "        self.suffix = suffix\n",
    "        self.folder_name = folder_name\n",
    "        self.sep = sep\n",
    "        self.term = term\n",
    "        self.basedir = BASEDIR\n",
    "        self.filepath = os.path.join(BASEDIR, self.folder_name)\n",
    "        self.filename = self.module_name + self.sep + self.typeofile + self.sep + self.term + self.sep + self.get_timestamp()\n",
    "        self.filepathandname = Path(self.filepath, self.filename).with_suffix(self.suffix)\n",
    "        self.make_dir()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'filepathandname:{str(self.filepathandname)}'\n",
    "    \n",
    "    def make_dir(self):\n",
    "        this_filepath = os.path.join(BASEDIR, self.filepath)\n",
    "        try:\n",
    "            os.mkdir(this_filepath)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "    def get_timestamp(self):\n",
    "        today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "        now = datetime.now().strftime(\"%H-%M-%S\")\n",
    "        return today + '_' + now\n",
    "\n",
    "# Creates and configures a log\n",
    "class Log:\n",
    "    def __init__(self, module_name='retailnlp', term='', level='INFO'):\n",
    "        self.module_name = module_name\n",
    "        self.log = logging.getLogger(module_name)\n",
    "        self.term = term\n",
    "        self.level = level\n",
    "        self.log.setLevel(self.level)\n",
    "        self.log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "        self.date_format = '%Y-%m-%d %H:%M:%S'\n",
    "        self.formatter = logging.Formatter(self.log_format, self.date_format)\n",
    "        self.log_write_mode = 'w+'\n",
    "        \n",
    "    @property\n",
    "    def log_filepathandname(self):\n",
    "        f = Filename(self.module_name, term=self.term)\n",
    "        return f.filepathandname\n",
    "    \n",
    "    def log_addfh(self):\n",
    "        self.file_handler = logging.FileHandler(self.log_filepathandname, self.log_write_mode)\n",
    "        self.file_handler.setFormatter(self.formatter)\n",
    "        self.log.addHandler(self.file_handler)\n",
    "    \n",
    "    def log_addch(self):\n",
    "        self.console_handler = logging.StreamHandler()\n",
    "        self.console_handler.setFormatter(self.formatter)\n",
    "        self.log.addHandler(self.console_handler)\n",
    "\n",
    "    def log_remove_handlers(self):\n",
    "        self.log.info('log_remove_handlers: Removing all existing log handlers')\n",
    "        # get all loggers\n",
    "        loggers = [logging.getLogger(name) if 'retail' in name else None for name in logging.root.manager.loggerDict]\n",
    "        # for each valid logger remove all handlers\n",
    "        for log in loggers:\n",
    "            if log != None:\n",
    "                while bool(len(log.handlers)):\n",
    "                    for handler in log.handlers:\n",
    "                        print('removing handler!')\n",
    "                        log.removeHandler(handler)\n",
    "\n",
    "#Load data from a csv file - create a df\n",
    "class LoadCSV:\n",
    "    def __init__(self, filename, projectname='', sep='\\t'):\n",
    "        self.project_name = projectname\n",
    "        self.filename = filename\n",
    "        self.sep = sep\n",
    "    \n",
    "    @property\n",
    "    def filepath(self):\n",
    "        return os.path.join(BASEDIR, 'data', self.filename)\n",
    "    \n",
    "    @property\n",
    "    def df(self):\n",
    "        df = pd.read_csv(self.filepath, self.sep, header=0, encoding='latin1', engine='python')\n",
    "        df.columns = df.columns.str.strip().str.upper().str.replace(r'\\s+', '_').str.replace('-', '_').str.replace('(', '').str.replace(')', '')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Product:\n",
    "    def __init__(self, product_number, result_page_number, result_page_index_position, product_name, product_description, web_selling_price, calculated_cost_price):\n",
    "        self.product_number = product_number\n",
    "        self.result_page_number = result_page_number\n",
    "        self.result_page_index_position = result_page_index_position \n",
    "        self.product_name = product_name\n",
    "        self.product_description = product_description\n",
    "        self.web_selling_price = web_selling_price\n",
    "        self.calculated_cost_price = calculated_cost_price\n",
    "\n",
    "    def __str__(self):\n",
    "        return\n",
    "        f'product_number={self.product_number}:'\n",
    "        + f'result_page_number={self.result_page_number}:'\n",
    "        + f'result_page_index_position={self.result_page_index_position}:'\n",
    "        + f'name={self.product_name}:description{self.product_name}:'\n",
    "        + f'name={self.product_description}:description{self.product_description}:'\n",
    "        + f'web_selling_price{self.web_selling_price}:'\n",
    "        + f'cost_price{self.calculated_cost_price}'\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'PRODUCT_NUMBER': self.product_number\n",
    "            ,'RESULT_PAGE_NUMBER': self.result_page_number\n",
    "            ,'RESULT_PAGE_INDEX_POSITION': self.result_page_index_position\n",
    "            ,'PRODUCT_NAME': self.product_name\n",
    "            ,'PRODUCT_DESCRIPTION': self.product_description\n",
    "            ,'WEB_SELLING_PRICE': self.web_selling_price\n",
    "            ,'CALCULATED_COST_PRICE': self.calculated_cost_price\n",
    "        }\n",
    "\n",
    "class Invoice:\n",
    "    def __init__(self, invoice_date):\n",
    "        self.invoice_number = random.sample(range(1000000),1)[0]\n",
    "        self.invoice_date = invoice_date\n",
    "        self.invoice_number_of_lines = random.randint(5,15)\n",
    "        self.invoice_lines = []\n",
    "        \n",
    "    def add_invoice_line(self, product, line_number):\n",
    "        invoice_line = InvoiceLine(self.invoice_number, self.invoice_date, line_number, product)\n",
    "        self.invoice_lines.append(invoice_line)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'invoice_number={self.invoice_number}:invoice_date={self.invoice_date}:number_invoice_lines={len(self.invoice_lines)}'\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'INVOICE_NUMBER': self.invoice_number\n",
    "            ,'INVOICE_DATE': self.invoice_date\n",
    "            ,'NUMBER_INVOICE_LINES': len(self.invoice_lines)\n",
    "        }\n",
    "    \n",
    "    def df(self, list_of_items):\n",
    "        return pd.DataFrame.from_records([i.to_dict for i in list_of_items])\n",
    "\n",
    "class InvoiceLine:\n",
    "    def __init__(self, invoice_number, invoice_date, invoice_line_number, product, original_product_description):\n",
    "        self.invoice_number = invoice_number\n",
    "        self.invoice_date = invoice_date\n",
    "        self.invoice_line_number = invoice_line_number\n",
    "        self.product = product\n",
    "        self.original_product_description = original_product_description\n",
    "    \n",
    "    def __str__(self):\n",
    "        return\n",
    "        f'invoice_number={self.invoice_number}:self.invoice_date={self.invoice_date}:self.invoice_line_number={self.invoice_line_number}:'\n",
    "        + f'self.product.name={self.product.name}:self.product.description={self.product.description}:'\n",
    "        + f'self.product.web_selling_price={self.product.web_selling_price}:'\n",
    "        + f'self.product.calculated_cost_price={self.product.calculated_cost_price}'\n",
    "        + f'self.original_product_description={self.original_product_description}'\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'INVOICE_NUMBER': self.invoice_number\n",
    "            ,'INVOICE_DATE': self.invoice_date\n",
    "            ,'INVOICE_LINE_NUMBER': self.invoice_line_number\n",
    "            ,'INVOICE_LINE_PRODUCT_NAME': self.product.product_name\n",
    "            ,'INVOICE_LINE_PRODUCT_DESCRIPTION': self.product.product_description\n",
    "            ,'INVOICE_LINE_PRODUCT_WEB_SELLING_PRICE': self.product.web_selling_price\n",
    "            ,'INVOICE_LINE_PRODUCT_CALCULATED_COST_PRICE': self.product.calculated_cost_price\n",
    "            ,'INVOICE_LINE_ORIGINAL_PRODUCT_DESCRIPTION': self.original_product_description\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_products(df_product_csv):\n",
    "    main_log.log.info('create_products: starting')\n",
    "    # Start with the webscraped products dataframe and delete all range priced products\n",
    "    df_non_range_products = df_product_csv.drop(df_product_csv[df_product_csv['FROM_PRICE'] != df_product_csv['TO_PRICE']].index)\n",
    "     # Select and rename required columns from web product data\n",
    "    df_products = df_non_range_products[['RESULT_PAGE_NUMBER', 'RESULT_PAGE_INDEX_POSITION', 'SEARCH_TERM', 'DESCRIPTION', 'FROM_PRICE']].copy()\n",
    "    df_products = df_products.rename(columns={'SEARCH_TERM': 'PRODUCT_NAME', 'DESCRIPTION': 'PRODUCT_DESCRIPTION', 'FROM_PRICE': 'WEB_SELLING_PRICE'})\n",
    "    # Create / mimic cost price by discounting selling price\n",
    "    df_products['CALCULATED_COST_PRICE'] = round(df_products['WEB_SELLING_PRICE'] * np.random.randint(85, 95, len(df_products))/100, 2)\n",
    "    list_of_products = [\n",
    "        Product(\n",
    "            str(row['RESULT_PAGE_NUMBER']) + '-' + str(row['RESULT_PAGE_INDEX_POSITION'])\n",
    "            ,row['RESULT_PAGE_NUMBER']\n",
    "            ,row['RESULT_PAGE_INDEX_POSITION']\n",
    "            ,row['PRODUCT_NAME']\n",
    "            ,row['PRODUCT_DESCRIPTION']\n",
    "            ,row['WEB_SELLING_PRICE']\n",
    "            ,row['CALCULATED_COST_PRICE']\n",
    "        )\n",
    "        for index, row in df_products.iterrows()\n",
    "    ]\n",
    "    main_log.log.info(f'create_products: ending: {len(list_of_products)} products created')\n",
    "    return list_of_products\n",
    "\n",
    "def create_invoices(number_of_products, number_of_invoices=20):\n",
    "    main_log.log.info('create_invoices: starting')\n",
    "    # Create empty lists to hold outputs\n",
    "    list_of_invoices = []\n",
    "    list_of_invoice_lines = []\n",
    "    # Iterate for number of invoices\n",
    "    for i in range(number_of_invoices):\n",
    "        invoice_date = datetime.now() - timedelta(days=i)\n",
    "        invoice = Invoice(invoice_date.date())\n",
    "        main_log.log.debug(f'create_invoices: invoice for date {invoice.invoice_date} created')\n",
    "        product_indexes = random.sample(range(number_of_products), invoice.invoice_number_of_lines)\n",
    "        # Iterate for number of invoice lines (a random number created on invoice instantiation)\n",
    "        for line_number in range(invoice.invoice_number_of_lines):\n",
    "            this_product = deepcopy(list_of_products[product_indexes[line_number]]) # Copy product entity using random index number ref to list of product entities\n",
    "            invoice_line = InvoiceLine(invoice.invoice_number, invoice.invoice_date, line_number, this_product, this_product.product_description) \n",
    "            invoice.invoice_lines.append(invoice_line)\n",
    "            # list_of_invoice_lines.append(invoice_line)\n",
    "            main_log.log.debug(f'create_invoices: invoice line for product {invoice_line.product.product_description} created')\n",
    "        list_of_invoices.append(invoice)\n",
    "    main_log.log.info(f'create_invoices: ending: {len(list_of_invoices)} invoices created')\n",
    "    return list_of_invoices\n",
    "\n",
    "def modify_invoice_line_product_descriptions(list_of_invoices):\n",
    "    for invoice in list_of_invoices:\n",
    "        for invoice_line in invoice.invoice_lines:\n",
    "            split_description = invoice_line.product.product_description.split(',')\n",
    "            if len(split_description) == 3:\n",
    "                invoice_line.product.product_description = split_description[1] + split_description[2]\n",
    "\n",
    "def fuzzymatch(df_products, df_invoice_lines):\n",
    "    main_log.log.debug(f'fuzzymatch: starting')\n",
    "    # Dedupe invoice line products\n",
    "    df_invoice_lines_fm = df_invoice_lines.copy()\n",
    "    main_log.log.debug(f'fuzzymatch:len df_invoice_lines_fm before dedupe={len(df_invoice_lines_fm)}')\n",
    "    df_invoice_lines_fm.drop_duplicates(subset=['INVOICE_LINE_PRODUCT_NAME', 'INVOICE_LINE_PRODUCT_DESCRIPTION'], keep='first', inplace=True)\n",
    "    save_df_as_csv(df_invoice_lines_fm, term='fm_deduped')\n",
    "    main_log.log.debug(f'fuzzymatch:len df_invoice_lines_fm after dedupe={len(df_invoice_lines_fm)}')\n",
    "    left_on = ['PRODUCT_NAME', 'PRODUCT_DESCRIPTION']\n",
    "    right_on = ['INVOICE_LINE_PRODUCT_NAME', 'INVOICE_LINE_PRODUCT_DESCRIPTION'] \n",
    "    matched_results = fuzzymatcher.fuzzy_left_join(df_products, df_invoice_lines_fm, left_on, right_on, left_id_col='PRODUCT_NUMBER', right_id_col = 'INVOICE_NUMBER')\n",
    "    main_log.log.debug(f'fuzzymatch: len matched_results={len(matched_results)}')\n",
    "    main_log.log.debug(f'fuzzymatch: ending')\n",
    "    return matched_results\n",
    "\n",
    "def recordlink(df_products, df_invoice_lines):\n",
    "    main_log.log.debug(f'recordlink: starting')\n",
    "    # Prep data for Record Linkage - df's need to have samne number of rows and have index set\n",
    "    # df_products.set_index('RESULT_PAGE_NUMBER', 'RESULT_PAGE_INDEX_POSITION')\n",
    "    df_products.set_index('RESULT_PAGE_NUMBER')\n",
    "    df_invoice_lines_rl = df_invoice_lines.copy()\n",
    "    # df_invoice_lines_rl.set_index('INVOICE_NUMBER', 'INVOICE_LINE_NUMBER')\n",
    "    df_invoice_lines_rl.set_index('INVOICE_NUMBER')\n",
    "    # Get distinct list of products held in invoice lines\n",
    "    main_log.log.debug(f'recordlink:len df_invoice_lines_rl before dedupe={len(df_invoice_lines_rl)}')\n",
    "    df_invoice_lines_rl.drop_duplicates(subset=['INVOICE_LINE_PRODUCT_NAME', 'INVOICE_LINE_PRODUCT_DESCRIPTION'], keep='first', inplace=True)\n",
    "    main_log.log.debug(f'recordlink:len df_invoice_lines_rl after dedupe={len(df_invoice_lines_rl)}')\n",
    "    save_df_as_csv(df_invoice_lines_rl, term='rl_deduped')\n",
    "    # number_additional_rows = len(df_products) - len(df_invoice_lines_rl)\n",
    "    # main_log.log.debug(f'recordlink: before append rows:number of addtl rows={number_additional_rows}:len of df_invoice_lines_rl={len(df_invoice_lines_rl)}:'\n",
    "    #     + f'len of df_products={len(df_products)}')\n",
    "    # for i in range(number_additional_rows):\n",
    "    #     dummy_value = 'dummy' + str(i)\n",
    "    #     new_row = pd.Series({'INVOICE_NUMBER': dummy_value, 'INVOICE_DATE': dummy_value, 'INVOICE_LINE_NUMBER': dummy_value, 'INVOICE_LINE_PRODUCT_NAME': dummy_value,                          'INVOICE_LINE_PRODUCT_DESCRIPTION': dummy_value, 'INVOICE_LINE_PRODUCT_WEB_SELLING_PRICE': dummy_value, 'INVOICE_LINE_PRODUCT_CALCULATED_COST_PRICE': dummy_value,          })\n",
    "    #     df_invoice_lines_rl = df_invoice_lines_rl.append(new_row, ignore_index=True)\n",
    "    # save_df_as_csv(df_invoice_lines_rl, term='deduped_in_line_dummies')\n",
    "    # main_log.log.debug(f'recordlink: after append rows:number of addtl rows={number_additional_rows}:len of df_invoice_lines_rl={len(df_invoice_lines_rl)}:'\n",
    "    #     + f'len of df_products={len(df_products)}')\n",
    "    \n",
    "    # Fuzzy match invoice descriptions stetching back x days to those on the 'product file' and rank each match\n",
    "    indexer = recordlinkage.Index()\n",
    "    indexer.full()\n",
    "    # indexer.block(left_on=['NAME'], right_on=['INVOICE_LINE_PRODUCT_NAME'])\n",
    "    candidate_links = indexer.index(df_products, df_invoice_lines_rl)\n",
    "    main_log.log.debug(f'recordlink: len candidate_links={len(candidate_links)}')\n",
    "    compare = recordlinkage.Compare()\n",
    "    compare.exact('PRODUCT_NAME', 'INVOICE_LINE_PRODUCT_NAME', label='PRODUCT_NAME')\n",
    "    compare.string('PRODUCT_DESCRIPTION', 'INVOICE_LINE_PRODUCT_DESCRIPTION', method='jarowinkler', threshold=0.7, label='PRODUCT_DESCRIPTION')\n",
    "    feature_vectors = compare.compute(candidate_links, df_products, df_invoice_lines_rl)\n",
    "    return feature_vectors\n",
    "\n",
    "def save_list_as_csv(list_of_items, term=''):\n",
    "    main_log.log.info(f'save_list_as_csv: number of items being saved={len(list_of_items)}')\n",
    "    df = pd.DataFrame.from_records([item.to_dict() for item in list_of_items])\n",
    "    filename = Filename(typeofile='data', suffix='.csv', folder_name='data', sep='_', term=term)\n",
    "    df.to_csv(filename.filepathandname, index=False, sep=\",\")\n",
    "    return df\n",
    "\n",
    "def save_df_as_csv(df, term=''):\n",
    "    main_log.log.info(f'save_df_as_csv: number of items being saved={len(df)}')\n",
    "    filename = Filename(typeofile='data', suffix='.csv', folder_name='data', sep='_', term=term)\n",
    "    df.to_csv(filename.filepathandname, index=False, sep=\",\")\n",
    "\n",
    "def classlist_to_df(list_of_items):\n",
    "    return pd.DataFrame.from_records([i.to_dict() for i in list_of_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-10-30 19:20:39 - retailnlp - INFO - ################ starting ################\n",
      "2020-10-30 19:20:39 - retailnlp - INFO - create_products: starting\n",
      "2020-10-30 19:20:39 - retailnlp - INFO - create_products: ending: 105 products created\n",
      "2020-10-30 19:20:39 - retailnlp - INFO - create_invoices: starting\n",
      "2020-10-30 19:20:39 - retailnlp - INFO - create_invoices: ending: 10 invoices created\n",
      "2020-10-30 19:20:39 - retailnlp - INFO - save_list_as_csv: number of items being saved=105\n",
      "2020-10-30 19:20:39 - retailnlp - INFO - save_list_as_csv: number of items being saved=10\n",
      "2020-10-30 19:20:39 - retailnlp - INFO - save_list_as_csv: number of items being saved=98\n",
      "2020-10-30 19:20:39 - retailnlp - INFO - save_df_as_csv: number of items being saved=38\n",
      "2020-10-30 19:20:39 - retailnlp - INFO - log_remove_handlers: Removing all existing log handlers\n",
      "removing handler!\n",
      "removing handler!\n"
     ]
    }
   ],
   "source": [
    "# sub_log = Log(module_name=main_log.module_name + '.sub', term='main.sub')\n",
    "main_log = Log(term='main', level='INFO')\n",
    "main_log.log_addfh()\n",
    "main_log.log_addch()\n",
    "main_log.log.info('################ starting ################')\n",
    "# Load Product data\n",
    "product_csv = LoadCSV(projectname='retailnlp', filename='products.csv', sep='\\t')\n",
    "# Create Products\n",
    "list_of_products = create_products(product_csv.df)\n",
    "list_of_invoices = create_invoices(len(list_of_products), number_of_invoices=10)\n",
    "# Modify description of invoice line products to enable fuzzy matching\n",
    "modify_invoice_line_product_descriptions(list_of_invoices)\n",
    "list_of_invoice_lines = [invoice_line for invoice in list_of_invoices for invoice_line in invoice.invoice_lines]\n",
    "# Save as CSV's return df's\n",
    "df_products = save_list_as_csv(list_of_products, term='products')\n",
    "df_invoices = save_list_as_csv(list_of_invoices, term='invoices')\n",
    "df_invoice_lines = save_list_as_csv(list_of_invoice_lines, term='invoice_lines')\n",
    "# Fuzzy match invoice descriptions stetching back x days to those on the 'product file' and rank each match\n",
    "matched_results = fuzzymatch(df_products, df_invoice_lines)\n",
    "# features = recordlink(df_products, df_invoice_lines)\n",
    "# Close\n",
    "main_log.log_remove_handlers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy match invoice descriptions stetching back x days to those on the 'product file' and rank each match\n",
    "features = fuzzymatch(df_products, df_invoice_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA, dfB = load_febrl4()\n",
    "dfA.sort_values(by=['rec_id'], inplace=True)\n",
    "dfB.sort_values(by=['rec_id'], inplace=True)\n",
    "\n",
    "# print(dfA.columns)\n",
    "# print(dfA.index)\n",
    "# print(dfA.sort_values(by=['rec_id'], inplace=True))\n",
    "\n",
    "# dfA.head().sort_values(by=['rec_id'], inplace=True)\n",
    "# dfB.head().sort_values(by=['rec-id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(candidate_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.full()\n",
    "pairs = indexer.index(dfA, dfB)\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.block('given_name')\n",
    "candidate_links = indexer.index(dfA, dfB)\n",
    "compare_cl = recordlinkage.Compare()\n",
    "\n",
    "compare_cl.exact('given_name', 'given_name', label='given_name')\n",
    "compare_cl.string('surname', 'surname', method='jarowinkler', threshold=0.85, label='surname')\n",
    "compare_cl.exact('date_of_birth', 'date_of_birth', label='date_of_birth')\n",
    "compare_cl.exact('suburb', 'suburb', label='suburb')\n",
    "compare_cl.exact('state', 'state', label='state')\n",
    "compare_cl.string('address_1', 'address_1', threshold=0.85, label='address_1')\n",
    "\n",
    "features = compare_cl.compute(candidate_links, dfA, dfB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordlink(df_products, df_invoice_lines):\n",
    "    main_log.log.debug(f'recordlink: starting')\n",
    "    # Prep data for Record Linkage - df's need to have samne number of rows and have index set\n",
    "    # df_products.set_index('RESULT_PAGE_NUMBER', 'RESULT_PAGE_INDEX_POSITION')\n",
    "    df_products.set_index('RESULT_PAGE_NUMBER')\n",
    "    df_invoice_lines_rl = df_invoice_lines.copy()\n",
    "    # df_invoice_lines_rl.set_index('INVOICE_NUMBER', 'INVOICE_LINE_NUMBER')\n",
    "    df_invoice_lines_rl.set_index('INVOICE_NUMBER')\n",
    "    # Get distinct list of products held in invoice lines\n",
    "    main_log.log.debug(f'recordlink:len df_invoice_lines_rl before dedupe={len(df_invoice_lines_rl)}')\n",
    "    df_invoice_lines_rl.drop_duplicates(subset=['INVOICE_LINE_PRODUCT_NAME', 'INVOICE_LINE_PRODUCT_DESCRIPTION'], keep='first', inplace=True)\n",
    "    main_log.log.debug(f'recordlink:len df_invoice_lines_rl after dedupe={len(df_invoice_lines_rl)}')\n",
    "    save_df_as_csv(df_invoice_lines_rl, term='deduped_in_line')\n",
    "    number_additional_rows = len(df_products) - len(df_invoice_lines_rl)\n",
    "    main_log.log.debug(f'recordlink: before append rows:number of addtl rows={number_additional_rows}:len of df_invoice_lines_rl={len(df_invoice_lines_rl)}:'\n",
    "        + f'len of df_products={len(df_products)}')\n",
    "    for i in range(number_additional_rows):\n",
    "        dummy_value = 'dummy' + str(i)\n",
    "        new_row = pd.Series({'INVOICE_NUMBER': dummy_value, 'INVOICE_DATE': dummy_value, 'INVOICE_LINE_NUMBER': dummy_value, 'INVOICE_LINE_PRODUCT_NAME': dummy_value,                          'INVOICE_LINE_PRODUCT_DESCRIPTION': dummy_value, 'INVOICE_LINE_PRODUCT_WEB_SELLING_PRICE': dummy_value, 'INVOICE_LINE_PRODUCT_CALCULATED_COST_PRICE': dummy_value, })\n",
    "        df_invoice_lines_rl = df_invoice_lines_rl.append(new_row, ignore_index=True)\n",
    "    save_df_as_csv(df_invoice_lines_rl, term='deduped_in_line_dummies')\n",
    "    main_log.log.debug(f'recordlink: after append rows:number of addtl rows={number_additional_rows}:len of df_invoice_lines_rl={len(df_invoice_lines_rl)}:'\n",
    "        + f'len of df_products={len(df_products)}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Fuzzy match invoice descriptions stetching back x days to those on the 'product file' and rank each match\n",
    "    indexer = recordlinkage.Index()\n",
    "    indexer.full()\n",
    "    # indexer.block(left_on=['NAME'], right_on=['INVOICE_LINE_PRODUCT_NAME'])\n",
    "    candidate_links = indexer.index(df_products, df_invoice_lines_rl)\n",
    "    main_log.log.debug(f'recordlink: len candidate_links={len(candidate_links)}')\n",
    "    compare = recordlinkage.Compare()\n",
    "    compare.exact('NAME', 'INVOICE_LINE_PRODUCT_NAME', label='PRODUCT NAME')\n",
    "    compare.string('DESCRIPTION', 'INVOICE_LINE_PRODUCT_DESCRIPTION', method='jarowinkler', threshold=0.7, label='PRODUCT DESCRIPTION')\n",
    "    feature_vectors = compare.compute(candidate_links, df_products, df_invoice_lines_rl)\n",
    "    return feature_vectors"
   ]
  }
 ]
}